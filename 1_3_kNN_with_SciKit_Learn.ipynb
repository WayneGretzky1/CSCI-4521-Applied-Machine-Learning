{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WayneGretzky1/CSCI-4521-Applied-Machine-Learning/blob/main/1_3_kNN_with_SciKit_Learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "sXGCUYZVWAAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load your data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/be-prado/csci4521/refs/heads/main/Seeds.csv\")\n",
        "names = list(df.columns) #Save column names"
      ],
      "metadata": {
        "id": "57bX1kKcWN1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose which data is featuers (X) and labels (y)\n",
        "X = df[ ['area','compactness'] ].to_numpy()\n",
        "y = df['wheat_type'].to_numpy()"
      ],
      "metadata": {
        "id": "yNpoesfdWhf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions!"
      ],
      "metadata": {
        "id": "lmeGIolT83bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X,y,test_percent):\n",
        "  numRows = y.size                     #number or rows in the entire dataset\n",
        "  splitPoint = int((1-test_percent)*numRows)  #the row index test_size% of the way through\n",
        "  p = np.random.permutation(numRows)   #array for shuffling data\n",
        "  X = X[p]\n",
        "  y = y[p]\n",
        "\n",
        "  #Training data array\n",
        "  X_train = X[:splitPoint]  # training features\n",
        "  y_train = y[:splitPoint]  # training labels\n",
        "\n",
        "  #Testing data array\n",
        "  X_test = X[splitPoint:]  # testing features\n",
        "  y_test = y[splitPoint:] # testing labels\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "s5jdUFoxUAwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nn_classify_sample(train_features, train_labels, new_feature):\n",
        "  dists = np.array([np.sum( (t-new_feature)**2) for t in train_features])\n",
        "  nearest = dists.argmin()\n",
        "  return train_labels[nearest]\n",
        "\n",
        "def nn_classify(train_features, train_labels, test_features):\n",
        "  num_result = test_features[:,0].size\n",
        "  result = np.ones(num_result)\n",
        "  for i in range(0,num_result):\n",
        "    result[i] = nn_classify_sample(train_features[:,0:2], train_labels, test_features[i])\n",
        "  return result"
      ],
      "metadata": {
        "id": "-tgF7-gZYUzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(classify, X_train, y_train, X_test, y_test):\n",
        "  pred = classify(X_train, y_train, X_test)\n",
        "  correct_pred = (pred == y_test)\n",
        "  total_preds = y_test.size\n",
        "  return correct_pred.sum()/total_preds"
      ],
      "metadata": {
        "id": "JZAKv8xrYftA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_accuracy(classifier, X, y, count = 200, split=0.33):\n",
        "  acc = 0\n",
        "  for _ in range(0,count):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,y,split)\n",
        "    acc += accuracy(classifier, X_train, y_train, X_test, y_test)\n",
        "  return acc/count"
      ],
      "metadata": {
        "id": "9Bk91ar3dXvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test our nearest neighbor with our train/test split"
      ],
      "metadata": {
        "id": "OyKNoPfcoriG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: create a train/test split where 1/3 of the data is used for testing\n"
      ],
      "metadata": {
        "id": "tUNVfFK0W5ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: use our helper functions to compute the accuracy of a NN model with the above split\n"
      ],
      "metadata": {
        "id": "LJs7YN3DYso1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: put both lines of code in the same block and run multiple times\n",
        "# Q: Why does each run have different accuracies each run?\n"
      ],
      "metadata": {
        "id": "icX1m_EVaAIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN implementation"
      ],
      "metadata": {
        "id": "q_rWq3bZ_LET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "aaQEAPCYbGE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: write a function that will use KNN to classify a whole array of test features\n",
        "# Hint: use a wrapper function so that it fits within our accuracy helper function!\n",
        "def knn_classifier(k):\n",
        "    def knn_classify(x_train, y_train, x_test):\n",
        "\n",
        "        return\n",
        "    return knn_classify"
      ],
      "metadata": {
        "id": "R89CtvhJaVmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: test it out with 2, 5, and 10 neighbors\n"
      ],
      "metadata": {
        "id": "SdsGjWZ0cJBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: test different amounts of neighbors with the cross-validation\n"
      ],
      "metadata": {
        "id": "8u71rz7nrISU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the best K"
      ],
      "metadata": {
        "id": "rhRaE8Blt9nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: find the best performing K testing every third value between 1 - 91\n"
      ],
      "metadata": {
        "id": "zYkITP0_e3lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "GK2r4gf2hJw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: use seaborn to plot a graph of the accuracies vs. ks\n",
        "# Hint: use sns.lineplot\n"
      ],
      "metadata": {
        "id": "9JQAJnc1hM_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you have named dataframes, seaborn labels them auotmatically\n",
        "# .... but this can be a pain sometimes\n",
        "# TODO: lets turn our lists into dataframes so seaborn will label them\n"
      ],
      "metadata": {
        "id": "IcL3F0uWiMId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Or we can just use matplotlibs pyplot package to control the labels and titles\n",
        "# TODO: try it now!\n",
        "# Hint: functions like plt.xlabel, plt.ylabel, and plt.title will be useful\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "LfD7eJgQh4th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: lets make another graph but this time lets compute the accuracy for both training and testing sets for different Ks\n",
        "ks = np.arange(1,51)\n",
        "test_acc_list = []\n",
        "train_acc_list = []\n"
      ],
      "metadata": {
        "id": "VYzzhSCxoadH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper for making a graph nicely\n",
        "from pylab import rcParams\n",
        "sns.set(font_scale=1.2)\n",
        "sns.set_style(\"white\") #whitegrid white dark darkgrid\n",
        "\n",
        "rcParams['figure.figsize'] = 8, 6\n",
        "result = pd.DataFrame( {\"k\":ks,\"Train.Acc\":train_acc_list,\"Test.Acc\":test_acc_list} )\n",
        "pd.melt(result, ['k'])\n",
        "sns.lineplot(x=\"k\",y=\"value\", hue='variable', data=pd.melt(result, ['k']))"
      ],
      "metadata": {
        "id": "BlvvM3dqqW_D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}