{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WayneGretzky1/CSCI-4521-Applied-Machine-Learning/blob/main/Copy_of_2_2_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and extract the data\n",
        "Data is in a zip file"
      ],
      "metadata": {
        "id": "E9CcmwoY1Uxc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIs6IoqSd3Dz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ab4ce1-7621-4ac0-9b60-e2d7b84abf77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-29 19:44:18--  https://raw.githubusercontent.com/be-prado/csci4521/refs/heads/main/20news-bydate.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14464277 (14M) [application/octet-stream]\n",
            "Saving to: ‘20news-bydate.tar.gz’\n",
            "\n",
            "\r20news-bydate.tar.g   0%[                    ]       0  --.-KB/s               \r20news-bydate.tar.g 100%[===================>]  13.79M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-09-29 19:44:18 (253 MB/s) - ‘20news-bydate.tar.gz’ saved [14464277/14464277]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://raw.githubusercontent.com/be-prado/csci4521/refs/heads/main/20news-bydate.tar.gz\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf 20news-bydate.tar.gz"
      ],
      "metadata": {
        "id": "uKE6Dkole9Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using SciKit-Learn's CountVectorizer\n"
      ],
      "metadata": {
        "id": "hWoW7gpG1c56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "BEMdRINDfMy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The parameter `min_df` controls effect words that are not used frequently (min_df = minimum document frequency).\n",
        " - If it is an integer, all words occurring less than that value will be dropped.\n",
        " - If it is a fraction, all words that occur less than that fraction of the overall dataset are be dropped.\n",
        "\n",
        "`max_df` works in a similar manner"
      ],
      "metadata": {
        "id": "9U1f4K9efv84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(min_df=1) #min_df=1 --> use all words"
      ],
      "metadata": {
        "id": "a9xSHagyftHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CountVectorizer?"
      ],
      "metadata": {
        "id": "spUna2RtXUTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider two sentences:"
      ],
      "metadata": {
        "id": "X2dwLKYvgqkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = [\"How to catch pokemon\", \"Which Pokemon is the hardest to catch?\"]"
      ],
      "metadata": {
        "id": "rwW49arVgNq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many uniuqe words between the two?\n",
        "  - Is `catch` and `catch?` the same word?\n",
        "  - Is `Pokemon` and `pokemon` the same word?\n",
        "  - Would `catch` and `catching` be the same word?"
      ],
      "metadata": {
        "id": "SFYoYjsngsc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: fit_transform the sentences then print the vocab\n",
        "X = vectorizer.fit_transform(content)\n",
        "\n",
        "vectorizer.get_feature_names_out()\n",
        "\n"
      ],
      "metadata": {
        "id": "n3wW8WzSgmnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e50899c2-116b-4108-aae3-73d89e5e3dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['catch', 'hardest', 'how', 'is', 'pokemon', 'the', 'to', 'which'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can turn each sentence into a \"bag of words\" ... for each sentence:\n",
        " - 1 is word is present\n",
        " - 0 is word is absent"
      ],
      "metadata": {
        "id": "DeKbMzxWhE1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.toarray())"
      ],
      "metadata": {
        "id": "Y0HPH_Z7X9pJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84965279-58b9-4c07-fd83-8fba99adc588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0 1 0 1 0 1 0]\n",
            " [1 1 0 1 1 1 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CountVectorizer on UseNet posts"
      ],
      "metadata": {
        "id": "sumRDan42Kpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "DIR = \"/content/20news-bydate-train/rec.sport.hockey\""
      ],
      "metadata": {
        "id": "n2ZWkdJeifg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posts = [open(os.path.join(DIR, filename)).read() for filename in os.listdir(DIR)]"
      ],
      "metadata": {
        "id": "g4je5THciUFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posts[50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "4W151couYXIi",
        "outputId": "fd920573-ea54-4dee-90b2-286ed34c7903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"From: wdsst3@cislabs.pitt.edu (William D Sands)\\nSubject: request for video in Pittsburgh area\\nKeywords: Sunday afternoon\\nOrganization: University of Pittsburgh\\nLines: 11\\n\\n\\n\\tThere was apparently a 30 minute special here on the Penguins' \\nseason on ABC (WTAE - channel 4), immediately preceding the opening \\ngame against the Devils on Sunday.  I only turned it on in time to \\nwatch the credits.  If anyone taped it and is willing to let me borrow \\nit to dub it, I would appreciate it.  I would be willing to come pick \\nit up, and I'll return it the next day and buy you a beer.  Please \\nrespond via e-mail.  Thanks a lot.\\n\\tOh yeah.  Was it any good?\\n\\t\\t\\t\\t\\t\\t-Billy\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: fit_transform the vectorizer with our new data\n",
        "X_train = vectorizer.fit_transform(posts)"
      ],
      "metadata": {
        "id": "OmsdSazzAPDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(posts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM5qxenbBHSg",
        "outputId": "6fad387f-7c53-4d23-8c39-293a3f628613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "UxmpSr7-YpNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1be973-8d8f-4ec3-fd58-7d0f96751f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 12914)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out())\n",
        "print(len(vectorizer.get_feature_names_out()))"
      ],
      "metadata": {
        "id": "HqHNvFiAY21L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e14af2c-04b3-4c8f-bc76-be716e2bf7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['00' '000' '000256' ... 'zupancic' 'zurich' 'zzzzzz']\n",
            "12914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: vectorize the sentence \"Should a team be added in Wisconsin?\"\n",
        "new_post = \"Should a team be added in Wisconsin?\"\n",
        "new_post_vec = vectorizer.transform([new_post])\n",
        "print(new_post_vec)"
      ],
      "metadata": {
        "id": "tAqh7x-8AYyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13800b74-e3e8-439f-db28-2c1b25054a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 6 stored elements and shape (1, 12914)>\n",
            "  Coords\tValues\n",
            "  (0, 1900)\t1\n",
            "  (0, 2610)\t1\n",
            "  (0, 6536)\t1\n",
            "  (0, 10730)\t1\n",
            "  (0, 11577)\t1\n",
            "  (0, 12665)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: get the names of features present\n",
        "vectorizer.get_feature_names_out()[1900]\n",
        "vectorizer.get_feature_names_out()[2610]\n",
        "vectorizer.get_feature_names_out()[6536]\n",
        "vectorizer.get_feature_names_out()[10730]\n",
        "vectorizer.get_feature_names_out()[11577]\n",
        "vectorizer.get_feature_names_out()[12665]"
      ],
      "metadata": {
        "id": "9Y0FKI4-ZRLh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c1b1907b-1b99-454c-b667-4516e779ef46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'wisconsin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding Nearest Neighbors\n",
        "\n",
        "`new_post_vec` is a feature vector, and we can try to find its nearest neighbors in the training set"
      ],
      "metadata": {
        "id": "4za_qpSw2bIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "c1SFYjDhmlVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dist_raw(v1, v2):\n",
        "  delta = v1-v2\n",
        "  return np.linalg.norm(delta)"
      ],
      "metadata": {
        "id": "maIrvuhtmoy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: find the distances between the new post and the vectors in our training set\n",
        "dists = [dist_raw(new_post_vec.toarray(), train_vec) for train_vec in X_train]"
      ],
      "metadata": {
        "id": "19vHS1mLAmO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: which post is the closest?\n",
        "best_match_ID = np.argmin(dists)\n",
        "print(best_match_ID)"
      ],
      "metadata": {
        "id": "bNGHLQuzAtMg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16211ed-7fb2-4347-c40c-9e02fc9ebb25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dists[best_match_ID]"
      ],
      "metadata": {
        "id": "6TeH7MaOaiGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf35b434-3fb7-445f-8d99-e07e4873dd0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(5.291502622129181)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "posts[best_match_ID]"
      ],
      "metadata": {
        "id": "qbU4P9ouamDG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "abb15575-9c62-461e-e01c-3110e36c25dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'From: khettry@r1w2.pub.utk.edu (23064RFL)\\nSubject: Testing!!!\\nOrganization: University of Tennessee Computing Center\\n\\tJust Testing!!\\nDistribution: usa\\nLines: 1\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmm. The querry document was `\"Should a new team be added to Wisconsin?\"`.\n",
        "\n",
        "Does this post seem related to our query feature? Let's check which elements of the feature vectors overlap."
      ],
      "metadata": {
        "id": "G1PU3Ia52yse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: print the query vector and the closest vector?\n",
        "print(X_train[best_match_ID])\n"
      ],
      "metadata": {
        "id": "HPdnRgLzBF9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccfd5b82-d535-4fb7-a9d1-cea484ac0e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 19 stored elements and shape (1, 12914)>\n",
            "  Coords\tValues\n",
            "  (0, 5633)\t1\n",
            "  (0, 11333)\t1\n",
            "  (0, 8805)\t1\n",
            "  (0, 12149)\t1\n",
            "  (0, 8685)\t1\n",
            "  (0, 7497)\t1\n",
            "  (0, 4851)\t1\n",
            "  (0, 6966)\t1\n",
            "  (0, 3371)\t1\n",
            "  (0, 4579)\t1\n",
            "  (0, 12209)\t1\n",
            "  (0, 3789)\t1\n",
            "  (0, 7085)\t1\n",
            "  (0, 9693)\t1\n",
            "  (0, 9607)\t1\n",
            "  (0, 12230)\t1\n",
            "  (0, 917)\t1\n",
            "  (0, 11651)\t2\n",
            "  (0, 11623)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_post_vec)"
      ],
      "metadata": {
        "id": "eeq-0uWHazZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1019b93-6fee-4446-f66e-190f50cb9805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 6 stored elements and shape (1, 12914)>\n",
            "  Coords\tValues\n",
            "  (0, 1900)\t1\n",
            "  (0, 2610)\t1\n",
            "  (0, 6536)\t1\n",
            "  (0, 10730)\t1\n",
            "  (0, 11577)\t1\n",
            "  (0, 12665)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That worked poorly... There is no overlap in features. What happened?"
      ],
      "metadata": {
        "id": "MlW5q5-9oUtU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normalized distance\n",
        "Normalizing vectors before computing distance focuses on document content rather than length"
      ],
      "metadata": {
        "id": "XpszVXHU3KBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dist_norm(v1, v2):\n",
        "  v1_normalized = v1/np.linalg.norm(v1) #Normalize vectors to unit length\n",
        "  v2_normalized = v2/np.linalg.norm(v2)\n",
        "  delta = v1_normalized-v2_normalized   #Then take distance\n",
        "  return np.linalg.norm(delta)"
      ],
      "metadata": {
        "id": "P_P5S6V8oQE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: find the normalized distances between the new post and the vectors in our training set then find the new closest post\n",
        "dists = [dist_norm(new_post_vec.toarray(), train_vec.toarray()) for train_vec in X_train]"
      ],
      "metadata": {
        "id": "d3q1J6iYoefA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_match_ID = np.argmin(dists)\n",
        "print(best_match_ID)"
      ],
      "metadata": {
        "id": "O3cayqQIbfjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a76bd6-7b46-432d-9d3f-9dfba20fdf73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "posts[best_match_ID]"
      ],
      "metadata": {
        "id": "sJTz0_rWbkxI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "722e406d-a2ed-4ad5-b9c3-f0234276f894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"From: jake@rambler.Eng.Sun.COM (Jason Cockroft)\\nSubject: Re: Playoff predictions\\nOrganization: Sun Microsystems, Inc.\\nLines: 95\\nDistribution: world\\nReply-To: jake@rambler.Eng.Sun.COM\\nNNTP-Posting-Host: rambler.eng.sun.com\\n\\n1st round: \\n----------\\n\\nPITT vs NYI:  PITT in 4. \\n\\nIt looks like a safe bet.  NYI has been bagging it of late.\\nNYI and NJD have a showdown Friday night for the honour\\nof Pittsburg anyway.  Pigsburg in 4.\\n\\nWASH vs NJD:  WASH in 6. \\nI think that NJD have a solid team and will compete with\\nWASH.  I agree though with WASH in 6.\\n\\nBOS  vs BUF:  BOS  in 5. \\nThe B's have been playing awesome hockey in the last\\ntwo weeks.  The only question is how long will it last?\\nFuhr is a dud.  BOS in 4.\\n\\nQUE  vs MON:  MON  in 7.\\nIt seems to me that MON is much like the VAN - no chemistry.\\nThe Habs seem to be not in stride. QUE in 5.  \\n\\nCHI  vs STL:  CHI in 4. \\nSTL should not be in the playoffs. CHI in 4.\\n\\nDET  vs TOR:  DET in 6.\\nI am a diehard Leaf fan but ... It seems that the Leafs\\noffense is shutting down in the last week.  Can they\\nturn it around against Detroit.  As I recall, the last\\ncouple of time these two teams met, the Leafs were pummelled.\\nI don't know if Bobbie is allowed in Canada yet.  If he is,\\nDET in 5.  If not, DET in 6.\\n\\nVAN  vs WIN:  WIN in 6.\\n\\nUpset in the making here.  Another team with bad chemistry.\\nThere is something gone foul among Linden, Momesso and Bure.\\nWIN in 6.\\n\\nCAL  vs  LA:  CAL in 5.\\nAnybody that says that LA could possibly beet CAL does\\nnot watch the Smythe a whole lot.  LA is a bunch of Geritols.\\nCAL in 4.\\n\\n\\n2nd round: \\n----------\\n\\nPITT vs WASH: PITT in 4. \\nIt seems to me that Pigsburg has some egos on their team.  Their\\nsaving grace though is Bowman.  He can put anybody in their place.\\nHowever, if PIGS have a quick first round, they may be a little\\ntoo high.  WASH could be there for a surprise.  Having said that,\\nI will say PITT in 6.\\n\\nBOS  vs MON:  BOS  in 6.\\nMON will not be there.  BOS is surprising me of late. Cam is great.\\nThe couple of wins against QUE last week have sold me with the\\nB's.  B's in 6.\\n\\n\\nCHI  vs DET:  CHI  in 7.\\nYikes.  This will not be pretty.  But DET is running like a machine\\nof late.  They've had a non-busy end of the season in which they played\\nlike killers.  DET in 6.\\n\\nWIN  vs CAL:  CAL  in 5.\\nCAL has a solid team, a little weak in the nets.  CAL will out\\nmuscle WIN.  CAL in 5.\\n\\n3rd round: \\n----------\\n\\nPITT vs BOS:  PITT in 5. \\n\\nI hate PITT.  My logic eludes me.  The dark side will take over\\nand give BOS the extra push it needs to dump PITT.  There may\\nbe something to this - if you think of the rivalry.  BOS in 7.\\nCHI  vs CAL:  CHI  in 5. \\n\\nFinals:\\n------\\n\\nPITT vs CHI: PITT in 5. \\n\\nNO, no, no.  We have BOS vs DET.  I don't know what to say\\nhere.  Both teams will be flying and overdue.  I will go\\nwith goaltending and muscle and say DET in 7.\\n\\n\\n-jake.\\n\\n\\n\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop Words, Stemming, and TF-IDF\n",
        "Ignoring common words (stop words)"
      ],
      "metadata": {
        "id": "BFOLmkJZqgNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(min_df=1, stop_words='english')"
      ],
      "metadata": {
        "id": "_GaL1JhAqaSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll lose some words now. The size of the feature vector should be smaller."
      ],
      "metadata": {
        "id": "qmqTGz74q_Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape #Old Vectorizations"
      ],
      "metadata": {
        "id": "bY2yEYzrq5gO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2014f47-1c51-4e82-868a-e84a3396623d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 12914)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = vectorizer.fit_transform(posts)"
      ],
      "metadata": {
        "id": "KK3_cNTZq8ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape #New Vectorizations"
      ],
      "metadata": {
        "id": "1a0FtKFVq90I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e604547b-d9d1-43ef-d6ae-cc3c3fb6ebff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 12633)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(vectorizer.get_stop_words())"
      ],
      "metadata": {
        "id": "KZquDC4xcbqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa65920-d51c-43c4-bf4c-a2b5b25a867e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'across',\n",
              " 'after',\n",
              " 'afterwards',\n",
              " 'again',\n",
              " 'against',\n",
              " 'all',\n",
              " 'almost',\n",
              " 'alone',\n",
              " 'along',\n",
              " 'already',\n",
              " 'also',\n",
              " 'although',\n",
              " 'always',\n",
              " 'am',\n",
              " 'among',\n",
              " 'amongst',\n",
              " 'amoungst',\n",
              " 'amount',\n",
              " 'an',\n",
              " 'and',\n",
              " 'another',\n",
              " 'any',\n",
              " 'anyhow',\n",
              " 'anyone',\n",
              " 'anything',\n",
              " 'anyway',\n",
              " 'anywhere',\n",
              " 'are',\n",
              " 'around',\n",
              " 'as',\n",
              " 'at',\n",
              " 'back',\n",
              " 'be',\n",
              " 'became',\n",
              " 'because',\n",
              " 'become',\n",
              " 'becomes',\n",
              " 'becoming',\n",
              " 'been',\n",
              " 'before',\n",
              " 'beforehand',\n",
              " 'behind',\n",
              " 'being',\n",
              " 'below',\n",
              " 'beside',\n",
              " 'besides',\n",
              " 'between',\n",
              " 'beyond',\n",
              " 'bill',\n",
              " 'both',\n",
              " 'bottom',\n",
              " 'but',\n",
              " 'by',\n",
              " 'call',\n",
              " 'can',\n",
              " 'cannot',\n",
              " 'cant',\n",
              " 'co',\n",
              " 'con',\n",
              " 'could',\n",
              " 'couldnt',\n",
              " 'cry',\n",
              " 'de',\n",
              " 'describe',\n",
              " 'detail',\n",
              " 'do',\n",
              " 'done',\n",
              " 'down',\n",
              " 'due',\n",
              " 'during',\n",
              " 'each',\n",
              " 'eg',\n",
              " 'eight',\n",
              " 'either',\n",
              " 'eleven',\n",
              " 'else',\n",
              " 'elsewhere',\n",
              " 'empty',\n",
              " 'enough',\n",
              " 'etc',\n",
              " 'even',\n",
              " 'ever',\n",
              " 'every',\n",
              " 'everyone',\n",
              " 'everything',\n",
              " 'everywhere',\n",
              " 'except',\n",
              " 'few',\n",
              " 'fifteen',\n",
              " 'fifty',\n",
              " 'fill',\n",
              " 'find',\n",
              " 'fire',\n",
              " 'first',\n",
              " 'five',\n",
              " 'for',\n",
              " 'former',\n",
              " 'formerly',\n",
              " 'forty',\n",
              " 'found',\n",
              " 'four',\n",
              " 'from',\n",
              " 'front',\n",
              " 'full',\n",
              " 'further',\n",
              " 'get',\n",
              " 'give',\n",
              " 'go',\n",
              " 'had',\n",
              " 'has',\n",
              " 'hasnt',\n",
              " 'have',\n",
              " 'he',\n",
              " 'hence',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hereafter',\n",
              " 'hereby',\n",
              " 'herein',\n",
              " 'hereupon',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'however',\n",
              " 'hundred',\n",
              " 'i',\n",
              " 'ie',\n",
              " 'if',\n",
              " 'in',\n",
              " 'inc',\n",
              " 'indeed',\n",
              " 'interest',\n",
              " 'into',\n",
              " 'is',\n",
              " 'it',\n",
              " 'its',\n",
              " 'itself',\n",
              " 'keep',\n",
              " 'last',\n",
              " 'latter',\n",
              " 'latterly',\n",
              " 'least',\n",
              " 'less',\n",
              " 'ltd',\n",
              " 'made',\n",
              " 'many',\n",
              " 'may',\n",
              " 'me',\n",
              " 'meanwhile',\n",
              " 'might',\n",
              " 'mill',\n",
              " 'mine',\n",
              " 'more',\n",
              " 'moreover',\n",
              " 'most',\n",
              " 'mostly',\n",
              " 'move',\n",
              " 'much',\n",
              " 'must',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'name',\n",
              " 'namely',\n",
              " 'neither',\n",
              " 'never',\n",
              " 'nevertheless',\n",
              " 'next',\n",
              " 'nine',\n",
              " 'no',\n",
              " 'nobody',\n",
              " 'none',\n",
              " 'noone',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'nothing',\n",
              " 'now',\n",
              " 'nowhere',\n",
              " 'of',\n",
              " 'off',\n",
              " 'often',\n",
              " 'on',\n",
              " 'once',\n",
              " 'one',\n",
              " 'only',\n",
              " 'onto',\n",
              " 'or',\n",
              " 'other',\n",
              " 'others',\n",
              " 'otherwise',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 'part',\n",
              " 'per',\n",
              " 'perhaps',\n",
              " 'please',\n",
              " 'put',\n",
              " 'rather',\n",
              " 're',\n",
              " 'same',\n",
              " 'see',\n",
              " 'seem',\n",
              " 'seemed',\n",
              " 'seeming',\n",
              " 'seems',\n",
              " 'serious',\n",
              " 'several',\n",
              " 'she',\n",
              " 'should',\n",
              " 'show',\n",
              " 'side',\n",
              " 'since',\n",
              " 'sincere',\n",
              " 'six',\n",
              " 'sixty',\n",
              " 'so',\n",
              " 'some',\n",
              " 'somehow',\n",
              " 'someone',\n",
              " 'something',\n",
              " 'sometime',\n",
              " 'sometimes',\n",
              " 'somewhere',\n",
              " 'still',\n",
              " 'such',\n",
              " 'system',\n",
              " 'take',\n",
              " 'ten',\n",
              " 'than',\n",
              " 'that',\n",
              " 'the',\n",
              " 'their',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'thence',\n",
              " 'there',\n",
              " 'thereafter',\n",
              " 'thereby',\n",
              " 'therefore',\n",
              " 'therein',\n",
              " 'thereupon',\n",
              " 'these',\n",
              " 'they',\n",
              " 'thick',\n",
              " 'thin',\n",
              " 'third',\n",
              " 'this',\n",
              " 'those',\n",
              " 'though',\n",
              " 'three',\n",
              " 'through',\n",
              " 'throughout',\n",
              " 'thru',\n",
              " 'thus',\n",
              " 'to',\n",
              " 'together',\n",
              " 'too',\n",
              " 'top',\n",
              " 'toward',\n",
              " 'towards',\n",
              " 'twelve',\n",
              " 'twenty',\n",
              " 'two',\n",
              " 'un',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 'upon',\n",
              " 'us',\n",
              " 'very',\n",
              " 'via',\n",
              " 'was',\n",
              " 'we',\n",
              " 'well',\n",
              " 'were',\n",
              " 'what',\n",
              " 'whatever',\n",
              " 'when',\n",
              " 'whence',\n",
              " 'whenever',\n",
              " 'where',\n",
              " 'whereafter',\n",
              " 'whereas',\n",
              " 'whereby',\n",
              " 'wherein',\n",
              " 'whereupon',\n",
              " 'wherever',\n",
              " 'whether',\n",
              " 'which',\n",
              " 'while',\n",
              " 'whither',\n",
              " 'who',\n",
              " 'whoever',\n",
              " 'whole',\n",
              " 'whom',\n",
              " 'whose',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'within',\n",
              " 'without',\n",
              " 'would',\n",
              " 'yet',\n",
              " 'you',\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: based on a new query post, which post in our dataset is closest?\n",
        "new_post = \"Would I get injured playing goalie?\"\n",
        "new_post_vec = vectorizer.transform([new_post])\n",
        "dists = [dist_norm(new_post_vec.toarray(), train_vec.toarray()) for train_vec in X_train]\n",
        "best_match_ID = np.argmin(dists)\n",
        "\n",
        "print(best_match_ID)\n",
        "print(posts[best_match_ID])"
      ],
      "metadata": {
        "id": "p4u96Ah-8f8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a5c78d-b8e8-4fa7-f771-c86b87feaca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "273\n",
            "From: drozinst@db.erau.edu (Drozinski Tim)\n",
            "Subject: Re: Ulf and all...\n",
            "Organization: Embry-Riddle Aeronautical University, Daytona Beach, FL USA\n",
            "Lines: 59\n",
            "NNTP-Posting-Host: alpha.db.erau.edu\n",
            "\n",
            "layfield@cpsc.ucalgary.ca (Colin Layfield) writes:\n",
            "\n",
            ">In article <1pdlksINNmq7@GIRAFFE.ZOO.CS.YALE.EDU> wuziyun%suned@cs.yale.edu (You wanna know?) writes:\n",
            ">>\n",
            ">>\n",
            ">>Let me give my two cents worth in this whole thing:\n",
            ">>\n",
            ">>  I am very sick of Pittsburg fans(and they are my second favorite team) \n",
            ">>talk about how \" why can't Bruins forget about Ulf Samuelsson when we have\n",
            ">>forgotten all about Adam Graves\"  Beside the obvious fact that Lemeuix's career\n",
            ">>was never endangered by Graves' slash while Neely is still bother by his injury,\n",
            ">>I think the most important reason is:\n",
            ">>\n",
            ">>        ADAM GRAVES HAS PLAYED CLEAN HOCKEY EVER SINCE!  WHILE ULF SAMULESSON\n",
            ">>        CONTINUES TO PLAY DIRTY(YES, TRYING TO HIT A PLAYER WHERE HE'S INJURED\n",
            ">>        IS DIRTY).  FANS HAVE CAN FORGET ABOUT ONE DIRTY PLAY BUT HOW CAN YOU\n",
            ">>        FORGET ABOUT ULF SAMULESSON WHEN EVERYNIGHT, WHEN I WATCH HOCKEY HIGH\n",
            ">>        LIGHTS, I GET REMINDED OF HOW DIRTY HE IS.\n",
            "\n",
            ">Hitting a player when he's injured is dirty?  Can you explain this statement?\n",
            ">Do you mean a player who was just injured on the ice(?) or do you mean a player\n",
            ">who is playing hurt.  If a player is hurt he should not bother playing because\n",
            ">I don't belive ANY PLAYER should be let up on just because they are playing\n",
            ">hurt.\n",
            "\n",
            ">I'm not an Ulf fan but at least I can spot the fact he is like Calgary's\n",
            ">Theoren Fleury in the respect that part of his game is to really piss other\n",
            ">players off as that's part of his job (But he lacks Ulf's size!).\n",
            "\n",
            "I AM an Ulf (and Pgh) fan, and what pisses me off about the whole Adam Graves/\n",
            "Ulf Samuesson debate is that Ulf plays hard-hitting hockey (nothing wrong with \n",
            "that) while Graves does what he does when the only way to win a game is to \n",
            "intentionally hurt someone (which bites!).\n",
            "\n",
            ">Players that REALLY piss me off are the ones who insist on hitting from behind\n",
            ">or try to go for the knees to injure the players.  This kind of garbage has\n",
            ">got to go (I would really like to see Muni get pasted as he is one of the\n",
            ">worst offenders).\n",
            "\n",
            "I thought they had instituted all kinds of new rules this season to stop crap \n",
            "like that?!?  Is it just me, or does the officiating just still stink to high\n",
            "heaven?  IMHO, if they could get rid of the existing refs, and institute a new\n",
            "system with more than one ref on the ice to keep an eye on the trouble-makers\n",
            "then a lot of these things would stop, and then the game would be ruled by the\n",
            "finnesse players:  Mario, Selanne, Bure, Messier, et.al...\n",
            "\n",
            ">Just my $0.02.\n",
            "\n",
            "> Colin Layfield            | \"Religion and Sex are power plays,\n",
            ">                           |  Manipulate the people for the money they pay,\n",
            "> The University of Calgary |  Selling Skin, Selling God\n",
            "> Computer Science          |  The numbers look the same on their CREDIT CARDS!\"\n",
            "> layfield@cpsc.ucalgary.ca |                          - Queensryche\n",
            "\n",
            "\n",
            "Tim Drozinski\n",
            "Embry-Riddle Aero. Univ.\n",
            "drozinst@erau.db.erau.edu\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How did this do?\n",
        "\n",
        "We can can also add stemming and tf-idf:"
      ],
      "metadata": {
        "id": "4B_S_paguWBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.stem\n",
        "english_stemmer = nltk.stem.SnowballStemmer('english')"
      ],
      "metadata": {
        "id": "2Npi4jJfA2rU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_stemmer.stem(\"happily\")"
      ],
      "metadata": {
        "id": "DtFQ11Jzdsu9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "69669512-322a-4156-e1d0-58b24d212e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happili'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StemmedCountVectorizer(CountVectorizer):\n",
        "   def build_analyzer(self):\n",
        "     analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
        "     return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))"
      ],
      "metadata": {
        "id": "T8YDUn6hA_pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = StemmedCountVectorizer(min_df=1, stop_words='english')\n",
        "X_train = vectorizer.fit_transform(posts)"
      ],
      "metadata": {
        "id": "meDYFD4DBxBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: based on a new query post, which post in our dataset is closest?\n",
        "new_post = \"Would I get injured playing goalie?\"\n",
        "new_post_vec = vectorizer.transform([new_post])\n",
        "dists = [dist_norm(new_post_vec.toarray(), train_vec.toarray()) for train_vec in X_train]\n",
        "best_match_ID = np.argmin(dists)\n",
        "\n",
        "print(best_match_ID)\n",
        "print(posts[best_match_ID])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhtAoxhfGF7n",
        "outputId": "e5ed7662-e23c-4ffc-bfdb-8f1e97b30c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "245\n",
            "From: apland@mala.bc.ca (Ron Apland)\n",
            "Subject: Re: plus minus stat\n",
            "Organization: Malaspina College\n",
            "Lines: 28\n",
            "\n",
            "In article <1993Apr15.161737.28377@sol.UVic.CA>, gballent@hudson.UVic.CA (Greg  Ballentine) writes:\n",
            "> \n",
            "> In article 1@tnclus.tele.nokia.fi, hahietanen@tnclus.tele.nokia.fi () writes:\n",
            ">>In article <1993Apr14.174139.6604@sol.UVic.CA>, gballent@vancouver.UVic.CA (Greg  Ballentine) writes:\n",
            ">>> \n",
            ">>> \n",
            ">>> +/- is a good stat because it is the only stat that I am aware of that\n",
            ">>> takes into account defensive play.  It isn't a measure of defensive\n",
            ">>> play- it takes into account offense and defence- all aspects of play.\n",
            ">>                                                   \n",
            ">>  If we are interested of real all-round players, the power play stats\n",
            ">>  should be considered, too. Because the power play is also one aspect \n",
            ">>  of play! There is still something to be done with these player evaluation\n",
            ">>  tools!!\n",
            "> \n",
            "> IMO any good player should score on power plays because of the man\n",
            "> advantage.  Very good power play scorers tend to become overrated\n",
            "> because their point totals are inflated by power play points.\n",
            "> +/- tends to expose these overrated players such as Brett Hull,\n",
            "> John Cullen and Dave Andreychuck.\n",
            "> \n",
            "> Given the opportunity to play power play consistently, any player can\n",
            "> inflate his totals.\n",
            "> \n",
            "> Gregmeister\n",
            "\n",
            "Except for Vancouver, of course.  Bure has a hard time scoring on that\n",
            "power play.  He's got 7 shorthanded goals and 13 pp goals I think!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "fMvzhOUnedsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "633ae193-53ca-4722-a539-b381cb454c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 10381)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
        "  def build_analyzer(self):\n",
        "    analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
        "    return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))"
      ],
      "metadata": {
        "id": "u74xxx5eCmoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = StemmedTfidfVectorizer(min_df=1, stop_words='english')\n",
        "X_train = vectorizer.fit_transform(posts)"
      ],
      "metadata": {
        "id": "WjYFtQpDDTQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: based on a new query post, which post in our dataset is closest?\n",
        "new_post = \"Would I get injured playing goalie?\"\n",
        "new_post_vec = vectorizer.transform([new_post])\n",
        "dists = [dist_norm(new_post_vec.toarray(), train_vec.toarray()) for train_vec in X_train]\n",
        "best_match_ID = np.argmin(dists)\n",
        "\n",
        "print(best_match_ID)\n",
        "print(posts[best_match_ID])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFF5lBDQGO0Y",
        "outputId": "65964b5f-2fe2-4064-f3fb-c13285fc978e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "273\n",
            "From: drozinst@db.erau.edu (Drozinski Tim)\n",
            "Subject: Re: Ulf and all...\n",
            "Organization: Embry-Riddle Aeronautical University, Daytona Beach, FL USA\n",
            "Lines: 59\n",
            "NNTP-Posting-Host: alpha.db.erau.edu\n",
            "\n",
            "layfield@cpsc.ucalgary.ca (Colin Layfield) writes:\n",
            "\n",
            ">In article <1pdlksINNmq7@GIRAFFE.ZOO.CS.YALE.EDU> wuziyun%suned@cs.yale.edu (You wanna know?) writes:\n",
            ">>\n",
            ">>\n",
            ">>Let me give my two cents worth in this whole thing:\n",
            ">>\n",
            ">>  I am very sick of Pittsburg fans(and they are my second favorite team) \n",
            ">>talk about how \" why can't Bruins forget about Ulf Samuelsson when we have\n",
            ">>forgotten all about Adam Graves\"  Beside the obvious fact that Lemeuix's career\n",
            ">>was never endangered by Graves' slash while Neely is still bother by his injury,\n",
            ">>I think the most important reason is:\n",
            ">>\n",
            ">>        ADAM GRAVES HAS PLAYED CLEAN HOCKEY EVER SINCE!  WHILE ULF SAMULESSON\n",
            ">>        CONTINUES TO PLAY DIRTY(YES, TRYING TO HIT A PLAYER WHERE HE'S INJURED\n",
            ">>        IS DIRTY).  FANS HAVE CAN FORGET ABOUT ONE DIRTY PLAY BUT HOW CAN YOU\n",
            ">>        FORGET ABOUT ULF SAMULESSON WHEN EVERYNIGHT, WHEN I WATCH HOCKEY HIGH\n",
            ">>        LIGHTS, I GET REMINDED OF HOW DIRTY HE IS.\n",
            "\n",
            ">Hitting a player when he's injured is dirty?  Can you explain this statement?\n",
            ">Do you mean a player who was just injured on the ice(?) or do you mean a player\n",
            ">who is playing hurt.  If a player is hurt he should not bother playing because\n",
            ">I don't belive ANY PLAYER should be let up on just because they are playing\n",
            ">hurt.\n",
            "\n",
            ">I'm not an Ulf fan but at least I can spot the fact he is like Calgary's\n",
            ">Theoren Fleury in the respect that part of his game is to really piss other\n",
            ">players off as that's part of his job (But he lacks Ulf's size!).\n",
            "\n",
            "I AM an Ulf (and Pgh) fan, and what pisses me off about the whole Adam Graves/\n",
            "Ulf Samuesson debate is that Ulf plays hard-hitting hockey (nothing wrong with \n",
            "that) while Graves does what he does when the only way to win a game is to \n",
            "intentionally hurt someone (which bites!).\n",
            "\n",
            ">Players that REALLY piss me off are the ones who insist on hitting from behind\n",
            ">or try to go for the knees to injure the players.  This kind of garbage has\n",
            ">got to go (I would really like to see Muni get pasted as he is one of the\n",
            ">worst offenders).\n",
            "\n",
            "I thought they had instituted all kinds of new rules this season to stop crap \n",
            "like that?!?  Is it just me, or does the officiating just still stink to high\n",
            "heaven?  IMHO, if they could get rid of the existing refs, and institute a new\n",
            "system with more than one ref on the ice to keep an eye on the trouble-makers\n",
            "then a lot of these things would stop, and then the game would be ruled by the\n",
            "finnesse players:  Mario, Selanne, Bure, Messier, et.al...\n",
            "\n",
            ">Just my $0.02.\n",
            "\n",
            "> Colin Layfield            | \"Religion and Sex are power plays,\n",
            ">                           |  Manipulate the people for the money they pay,\n",
            "> The University of Calgary |  Selling Skin, Selling God\n",
            "> Computer Science          |  The numbers look the same on their CREDIT CARDS!\"\n",
            "> layfield@cpsc.ucalgary.ca |                          - Queensryche\n",
            "\n",
            "\n",
            "Tim Drozinski\n",
            "Embry-Riddle Aero. Univ.\n",
            "drozinst@erau.db.erau.edu\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "efvbSCPoekz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: with these new vectorizers, lets test that query post again\n"
      ],
      "metadata": {
        "id": "nEYUAxrJ-_ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cosine Similarity\n",
        "\n",
        "We can use the cosine similarity instead of the normalized vector distance.\n",
        "\n",
        "But remember to maximize similarity vs. minimize distance."
      ],
      "metadata": {
        "id": "QZvoM8SH4WTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_similarity(v1, v2):\n",
        "  return np.vdot(v1,v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
      ],
      "metadata": {
        "id": "obmUosM7Dnpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: use cosine similarity as a distance metric and try the query post again\n",
        "# TODO: based on a new query post, which post in our dataset is closest?\n",
        "new_post = \"Would I get injured playing goalie?\"\n",
        "new_post_vec = vectorizer.transform([new_post])\n",
        "dists = [dist_norm(new_post_vec.toarray(), train_vec.toarray()) for train_vec in X_train]\n",
        "best_match_ID = np.argmax(dists)\n",
        "\n",
        "print(best_match_ID)\n",
        "print(posts[best_match_ID])"
      ],
      "metadata": {
        "id": "5lujC_X0_ISd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c5d3aa-1893-4b38-c3eb-15ce3da82b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "278\n",
            "From: andrew@idacom.hp.com (Andrew Scott)\n",
            "Subject: USENET Hockey Draft week 27 price list\n",
            "Organization: Hewlett-Packard, IDACOM Telecommunications Division\n",
            "Lines: 264\n",
            "\n",
            "Here is the price list for the week April 13 to April 19.\n",
            "\n",
            "\t- Andrew\n",
            "\n",
            "Buy\tSell\tPts\tTeam\tPlayer\n",
            "158.9\t143.0\t157\tPIT\tMario_Lemieux\n",
            "148.5\t133.7\t145\tBUF\tPat_LaFontaine\n",
            "142.7\t128.4\t141\tBOS\tAdam_Oates\n",
            "137.6\t123.8\t136\tDET\tSteve_Yzerman\n",
            "132.1\t118.9\t129\tWPG\tTeemu_Selanne\n",
            "131.7\t118.5\t127\tNYI\tPierre_Turgeon\n",
            "130.1\t117.1\t127\tTOR\tDoug_Gilmour\n",
            "126.0\t113.4\t123\tBUF\tAlexander_Mogilny\n",
            "123.4\t111.1\t119\tPHI\tMark_Recchi\n",
            "121.9\t109.7\t119\tLA\tLuc_Robitaille\n",
            "113.3\t102.0\t112\tQUE\tMats_Sundin\n",
            "111.3\t100.2\t110\tPIT\tKevin_Stevens\n",
            "110.6\t99.5\t108\tVAN\tPavel_Bure\n",
            "108.6\t97.7\t106\tSTL\tCraig_Janney\n",
            "108.3\t97.5\t107\tPIT\tRick_Tocchet\n",
            "107.6\t96.8\t105\tCHI\tJeremy_Roenick\n",
            "105.3\t94.8\t104\tQUE\tJoe_Sakic\n",
            "103.5\t93.2\t101\tSTL\tBrett_Hull\n",
            "102.4\t92.2\t100\tCGY\tTheoren_Fleury\n",
            "101.2\t91.1\t100\tPIT\tRon_Francis\n",
            "100.4\t90.4\t98\tTOR\tDave_Andreychuk\n",
            "100.2\t90.2\t99\tBOS\tJoe_Juneau\n",
            "98.3\t88.5\t96\tWPG\tPhil_Housley\n",
            "98.3\t88.5\t96\tMTL\tVincent_Damphousse\n",
            "96.3\t86.7\t94\tMTL\tKirk_Muller\n",
            "96.1\t86.5\t95\tDET\tDino_Ciccarelli\n",
            "95.3\t85.8\t93\tBUF\tDale_Hawerchuk\n",
            "95.3\t85.8\t93\tMIN\tMike_Modano\n",
            "94.4\t85.0\t91\tNYR\tMark_Messier\n",
            "93.2\t83.9\t91\tSTL\tBrendan_Shanahan\n",
            "93.1\t83.8\t92\tPIT\tJaromir_Jagr\n",
            "88.1\t79.3\t86\tMTL\tBrian_Bellows\n",
            "88.1\t79.3\t86\tLA\tJari_Kurri\n",
            "88.0\t79.2\t87\tDET\tSergei_Fedorov\n",
            "87.1\t78.4\t85\tCGY\tRobert_Reichel\n",
            "87.0\t78.3\t86\tDET\tPaul_Coffey\n",
            "86.1\t77.5\t83\tWSH\tPeter_Bondra\n",
            "86.1\t77.5\t83\tHFD\tGeoff_Sanderson\n",
            "86.0\t77.4\t84\tTB\tBrian_Bradley\n",
            "85.0\t76.5\t82\tNYI\tSteve_Thomas\n",
            "84.0\t75.6\t83\tPIT\tLarry_Murphy\n",
            "84.0\t75.6\t81\tPHI\tRod_Brind'Amour\n",
            "83.0\t74.7\t82\tBOS\tRay_Bourque\n",
            "83.0\t74.7\t82\tQUE\tSteve_Duchesne\n",
            "83.0\t74.7\t80\tHFD\tAndrew_Cassels\n",
            "82.0\t73.8\t80\tLA\tTony_Granato\n",
            "81.9\t73.7\t79\tWSH\tDale_Hunter\n",
            "81.9\t73.7\t79\tWSH\tMike_Ridley\n",
            "80.9\t72.8\t78\tHFD\tPat_Verbeek\n",
            "80.9\t72.8\t79\tMTL\tStephan_Lebeau\n",
            "80.9\t72.8\t79\tCGY\tGary_Suter\n",
            "78.9\t71.0\t77\tVAN\tCliff_Ronning\n",
            "78.9\t71.0\t77\tNJ\tClaude_Lemieux\n",
            "78.9\t71.0\t78\tQUE\tMike_Ricci\n",
            "77.9\t70.1\t76\tVAN\tMurray_Craven\n",
            "77.9\t70.1\t76\tSTL\tJeff_Brown\n",
            "77.8\t70.0\t75\tWSH\tKevin_Hatcher\n",
            "77.8\t70.0\t75\tNYR\tTony_Amonte\n",
            "76.9\t69.2\t76\tSJ\tKelly_Kisio\n",
            "76.8\t69.1\t75\tNJ\tAlexander_Semak\n",
            "76.8\t69.1\t75\tMIN\tRuss_Courtnall\n",
            "75.8\t68.2\t74\tMIN\tDave_Gagner\n",
            "75.8\t68.2\t74\tTOR\tNikolai_Borschevsky\n",
            "75.7\t68.1\t73\tPHI\tEric_Lindros\n",
            "74.8\t67.3\t73\tLA\tJimmy_Carson\n",
            "73.8\t66.4\t72\tCGY\tJoe_Nieuwendyk\n",
            "73.8\t66.4\t72\tVAN\tGeoff_Courtnall\n",
            "73.8\t66.4\t72\tMIN\tUlf_Dahlen\n",
            "73.6\t66.2\t71\tNYI\tDerek_King\n",
            "73.6\t66.2\t71\tWSH\tMichal_Pivonka\n",
            "72.9\t65.6\t72\tQUE\tOwen_Nolan\n",
            "72.9\t65.6\t72\tBOS\tDmitri_Kvartalnov\n",
            "72.7\t65.4\t71\tSTL\tNelson_Emerson\n",
            "72.7\t65.4\t71\tCHI\tChris_Chelios\n",
            "72.6\t65.3\t70\tNYI\tBenoit_Hogue\n",
            "71.7\t64.5\t70\tNJ\tStephane_Richer\n",
            "71.7\t64.5\t70\tWPG\tThomas_Steen\n",
            "71.7\t64.5\t70\tWPG\tAlexei_Zhamnov\n",
            "71.7\t64.5\t70\tCHI\tSteve_Larmer\n",
            "69.8\t62.8\t69\tPIT\tJoe_Mullen\n",
            "69.5\t62.6\t67\tNYR\tMike_Gartner\n",
            "68.6\t61.7\t67\tVAN\tPetr_Nedved\n",
            "68.6\t61.7\t67\tVAN\tTrevor_Linden\n",
            "68.6\t61.7\t67\tLA\tMike_Donnelly\n",
            "68.4\t61.6\t66\tWSH\tDmitri_Khristich\n",
            "68.4\t61.6\t66\tWSH\tAl_Iafrate\n",
            "66.8\t60.1\t66\tDET\tRay_Sheppard\n",
            "66.8\t60.1\t66\tQUE\tAndrei_Kovalenko\n",
            "66.4\t59.8\t64\tHFD\tZarley_Zalapski\n",
            "66.4\t59.8\t64\tNYR\tAdam_Graves\n",
            "65.8\t59.2\t65\tSJ\tJohan_Garpenlov\n",
            "64.5\t58.1\t63\tTOR\tGlenn_Anderson\n",
            "63.5\t57.2\t62\tLA\tWayne_Gretzky\n",
            "63.5\t57.2\t62\tOTT\tNorm_Maciver\n",
            "62.2\t56.0\t60\tPHI\tGarry_Galley\n",
            "61.7\t55.5\t61\tDET\tSteve_Chiasson\n",
            "61.7\t55.5\t61\tDET\tPaul_Ysebaert\n",
            "61.5\t55.4\t60\tNJ\tValeri_Zelepukin\n",
            "61.5\t55.4\t60\tMTL\tMike_Keane\n",
            "61.2\t55.1\t59\tPHI\tBrent_Fedyk\n",
            "60.7\t54.6\t60\tPIT\tShawn_McEachern\n",
            "60.4\t54.4\t59\tLA\tRob_Blake\n",
            "60.1\t54.1\t58\tNYI\tPat_Flatley\n",
            "59.7\t53.7\t59\tQUE\tScott_Young\n",
            "59.4\t53.5\t58\tWPG\tDarrin_Shannon\n",
            "59.1\t53.2\t57\tPHI\tKevin_Dineen\n",
            "58.4\t52.6\t57\tNJ\tBernie_Nicholls\n",
            "58.4\t52.6\t57\tCGY\tSergei_Makarov\n",
            "58.4\t52.6\t57\tCHI\tSteve_Smith\n",
            "58.1\t52.3\t56\tWSH\tPat_Elynuik\n",
            "57.4\t51.7\t56\tVAN\tGreg_Adams\n",
            "57.4\t51.7\t56\tNJ\tScott_Stevens\n",
            "57.4\t51.7\t56\tTB\tJohn_Tucker\n",
            "56.3\t50.7\t55\tWPG\tFredrik_Olausson\n",
            "56.0\t50.4\t54\tNYR\tSergei_Nemchinov\n",
            "55.0\t49.5\t53\tNYR\tDarren_Turcotte\n",
            "55.0\t48.9\t53\tCGY\tAl_MacInnis\n",
            "55.0\t48.9\t53\tCHI\tChristian_Ruuttu\n",
            "55.0\t48.0\t52\tCHI\tBrent_Sutter\n",
            "55.0\t47.6\t51\tHFD\tTerry_Yake\n",
            "55.0\t47.0\t51\tVAN\tDixon_Ward\n",
            "55.0\t47.0\t51\tWPG\tKeith_Tkachuk\n",
            "55.0\t46.4\t51\tBOS\tStephen_Leach\n",
            "55.0\t46.1\t50\tTOR\tJohn_Cullen\n",
            "55.0\t46.1\t50\tMTL\tDenis_Savard\n",
            "55.0\t45.7\t49\tNYR\tEd_Olczyk\n",
            "55.0\t45.2\t49\tVAN\tAnatoli_Semenov\n",
            "55.0\t44.8\t48\tWSH\tSylvain_Cote\n",
            "55.0\t44.8\t48\tNYI\tVladimir_Malakhov\n",
            "55.0\t44.8\t48\tNYI\tJeff_Norton\n",
            "55.0\t44.8\t48\tHFD\tPatrick_Poulin\n",
            "55.0\t44.6\t49\tBOS\tDave_Poulin\n",
            "55.0\t44.3\t48\tLA\tTomas_Sandstrom\n",
            "55.0\t44.3\t48\tEDM\tPetr_Klima\n",
            "55.0\t44.3\t48\tNJ\tJohn_MacLean\n",
            "55.0\t44.3\t48\tEDM\tDoug_Weight\n",
            "55.0\t43.3\t47\tMTL\tGilbert_Dionne\n",
            "55.0\t43.3\t47\tLA\tAlexei_Zhitnik\n",
            "55.0\t43.3\t47\tEDM\tShayne_Corson\n",
            "55.0\t42.8\t47\tQUE\tMartin_Rucinsky\n",
            "55.0\t42.4\t46\tWPG\tEvgeny_Davydov\n",
            "55.0\t42.4\t46\tSTL\tKevin_Miller\n",
            "55.0\t42.4\t46\tEDM\tCraig_Simpson\n",
            "55.0\t42.0\t45\tWSH\tKelly_Miller\n",
            "55.0\t42.0\t45\tPHI\tPelle_Eklund\n",
            "55.0\t40.6\t44\tCHI\tMichel_Goulet\n",
            "55.0\t40.6\t44\tEDM\tDave_Manson\n",
            "55.0\t39.6\t43\tOTT\tSylvain_Turgeon\n",
            "55.0\t38.7\t42\tCGY\tPaul_Ranheim\n",
            "55.0\t38.7\t42\tMTL\tMathieu_Schneider\n",
            "55.0\t38.7\t42\tMIN\tMark_Tinordi\n",
            "55.0\t38.3\t42\tDET\tBob_Probert\n",
            "55.0\t37.8\t41\tEDM\tTodd_Elik\n",
            "55.0\t37.4\t40\tNYR\tEsa_Tikkanen\n",
            "55.0\t37.4\t41\tBOS\tVladimir_Ruzicka\n",
            "55.0\t36.9\t40\tOTT\tBob_Kudelski\n",
            "55.0\t36.9\t40\tNJ\tPeter_Stastny\n",
            "55.0\t36.9\t40\tTOR\tDave_Ellett\n",
            "55.0\t36.9\t40\tOTT\tBrad_Shaw\n",
            "55.0\t36.5\t40\tDET\tNiklas_Lidstrom\n",
            "55.0\t36.0\t39\tNJ\tBobby_Holik\n",
            "55.0\t36.0\t39\tTOR\tWendel_Clark\n",
            "55.0\t35.5\t38\tNYR\tAlexei_Kovalev\n",
            "55.0\t35.0\t38\tBUF\tYuri_Khmylev\n",
            "55.0\t35.0\t38\tMIN\tMike_McPhee\n",
            "55.0\t34.1\t37\tTOR\tRob_Pearson\n",
            "55.0\t34.1\t37\tVAN\tSergio_Momesso\n",
            "55.0\t33.6\t36\tNYR\tBrian_Leetch\n",
            "55.0\t33.2\t36\tCHI\tDirk_Graham\n",
            "55.0\t33.2\t36\tTB\tAdam_Creighton\n",
            "55.0\t32.8\t36\tQUE\tValery_Kamensky\n",
            "55.0\t32.3\t35\tEDM\tZdeno_Ciger\n",
            "55.0\t32.3\t35\tLA\tCorey_Millen\n",
            "55.0\t31.9\t35\tBOS\tTed_Donato\n",
            "55.0\t31.3\t34\tTOR\tPeter_Zezel\n",
            "55.0\t30.4\t33\tMIN\tNeal_Broten\n",
            "55.0\t29.5\t32\tMTL\tGary_Leeman\n",
            "55.0\t29.5\t32\tEDM\tScott_Mellanby\n",
            "55.0\t29.5\t32\tBUF\tWayne_Presley\n",
            "55.0\t29.2\t32\tDET\tKeith_Primeau\n",
            "55.0\t28.9\t31\tNYI\tBrian_Mullen\n",
            "55.0\t28.9\t31\tPHI\tJosef_Beranek\n",
            "55.0\t28.6\t31\tCHI\tStephane_Matteau\n",
            "55.0\t28.3\t31\tBOS\tSteve_Heinze\n",
            "55.0\t28.0\t30\tPHI\tDmitri_Yushkevich\n",
            "55.0\t28.0\t30\tHFD\tMikael_Nylander\n",
            "55.0\t27.6\t30\tBUF\tRichard_Smehlik\n",
            "55.0\t27.6\t30\tTOR\tDmitri_Mironov\n",
            "55.0\t25.8\t28\tCHI\tBrian_Noonan\n",
            "55.0\t25.5\t28\tSJ\tPat_Falloon\n",
            "55.0\t24.9\t27\tSTL\tIgor_Korolev\n",
            "55.0\t24.3\t26\tWSH\tBob_Carpenter\n",
            "55.0\t24.3\t26\tNYR\tJames_Patrick\n",
            "55.0\t23.9\t26\tBUF\tPetr_Svoboda\n",
            "55.0\t23.0\t25\tOTT\tMark_Lamb\n",
            "55.0\t22.4\t24\tNYI\tScott_LaChance\n",
            "55.0\t22.1\t24\tMTL\tBenoit_Brunet\n",
            "55.0\t22.1\t24\tTB\tMikael_Andersson\n",
            "55.0\t21.2\t23\tEDM\tMartin_Gelinas\n",
            "55.0\t21.2\t23\tWPG\tSergei_Bautin\n",
            "55.0\t21.2\t23\tTOR\tBill_Berg\n",
            "55.0\t21.2\t23\tEDM\tKevin_Todd\n",
            "55.0\t19.6\t21\tNYI\tDavid_Volek\n",
            "55.0\t19.6\t21\tNYI\tRay_Ferraro\n",
            "55.0\t19.4\t21\tMIN\tBrent_Gilchrist\n",
            "55.0\t18.6\t20\tHFD\tYvon_Corriveau\n",
            "55.0\t18.6\t20\tNYR\tPhil_Bourque\n",
            "55.0\t18.6\t20\tNYI\tDarius_Kasparaitis\n",
            "55.0\t18.2\t20\tDET\tJim_Hiller\n",
            "55.0\t17.7\t19\tPHI\tAndrei_Lomakin\n",
            "55.0\t17.6\t19\tBUF\tDonald_Audette\n",
            "55.0\t16.6\t18\tTB\tRoman_Hamrlik\n",
            "55.0\t15.5\t17\tBOS\tCam_Neely\n",
            "55.0\t15.5\t17\tSJ\tMark_Pederson\n",
            "55.0\t14.6\t16\tPIT\tMartin_Straka\n",
            "55.0\t13.9\t15\tCHI\tJoe_Murphy\n",
            "55.0\t12.2\t13\tNYR\tPeter_Andersson\n",
            "55.0\t12.0\t13\tOTT\tTomas_Jelinek\n",
            "55.0\t12.0\t13\tNJ\tJanne_Ojanen\n",
            "55.0\t10.2\t11\tTB\tSteve_Kasper\n",
            "55.0\t10.2\t11\tMIN\tBobby_Smith\n",
            "55.0\t9.1\t10\tSJ\tRay_Whitney\n",
            "55.0\t8.4\t9\tHFD\tRobert_Petrovicky\n",
            "55.0\t8.3\t9\tBUF\tViktor_Gordijuk\n",
            "55.0\t7.4\t8\tTOR\tJoe_Sacco\n",
            "55.0\t7.3\t8\tQUE\tMikhail_Tatarinov\n",
            "55.0\t7.3\t8\tSJ\tPeter_Ahola\n",
            "55.0\t6.5\t7\tCHI\tRob_Brown\n",
            "55.0\t6.4\t7\tBOS\tGlen_Murray\n",
            "55.0\t5.6\t6\tHFD\tTim_Kerr\n",
            "55.0\t5.5\t6\tMIN\tBrian_Propp\n",
            "55.0\t4.7\t5\tWSH\tReggie_Savage\n",
            "55.0\t4.6\t5\tSTL\tVitali_Prokhorov\n",
            "55.0\t4.6\t5\tLA\tRobert_Lang\n",
            "55.0\t4.6\t5\tEDM\tShaun_Van_Allen\n",
            "55.0\t3.7\t4\tMIN\tDan_Quinn\n",
            "55.0\t3.6\t4\tDET\tViacheslav_Kozlov\n",
            "55.0\t3.6\t4\tBOS\tJozef_Stumpel\n",
            "55.0\t3.6\t4\tPIT\tBryan_Fogarty\n",
            "55.0\t2.8\t3\tMTL\tOlav_Petrov\n",
            "55.0\t2.8\t3\tTB\tStan_Drulia\n",
            "55.0\t1.9\t2\tWSH\tJason_Woolley\n",
            "55.0\t1.8\t2\tNJ\tClaude_Vilgrain\n",
            "55.0\t0.0\t0\tMTL\tPatrick_Kjellberg\n",
            "55.0\t0.0\t0\tOTT\tAlexei_Yashin\n",
            "55.0\t0.0\t0\tWSH\tRandy_Burridge\n",
            "55.0\t0.0\t0\tEDM\tDean_McAmmond\n",
            "55.0\t0.0\t0\tCGY\tCory_Stillman\n",
            "55.0\t0.0\t0\tTB\tBrent_Gretzky\n",
            "55.0\t0.0\t0\tBUF\tJason_Dawe\n",
            "55.0\t0.0\t0\tWSH\tBrian_Sakic\n",
            "55.0\t0.0\t0\tVAN\tIgor_Larionov\n",
            "55.0\t0.0\t0\tCHI\tSergei_Krivokrasov\n",
            "55.0\t0.0\t0\tQUE\tPeter_Forsberg\n",
            "-- \n",
            "Andrew Scott                    | andrew@idacom.hp.com\n",
            "HP IDACOM Telecom Operation     | (403) 462-0666 ext. 253\n",
            "\n",
            "During the Roman Era, 28 was considered old...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Closest Document Function"
      ],
      "metadata": {
        "id": "JXNkt3574i3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function!\n",
        "def findClosestStory(promt):\n",
        "  new_post_vec = vectorizer.transform([promt])\n",
        "  dists = [cos_similarity(new_post_vec.toarray(),train_vec.toarray()) for train_vec in X_train]\n",
        "  closest_id = np.argmax(dists) #switch to arg max!\n",
        "  return posts[closest_id]\n"
      ],
      "metadata": {
        "id": "kkPP4P30HQZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(findClosestStory(\"What was the name of the player that scored for the Minnesota wild?\"))"
      ],
      "metadata": {
        "id": "tHFFWIBNfewX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cd96782-7c8e-4e6f-bc46-3b500fdc66ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: hamlet@stein.u.washington.edu (Mitch McGowan)\n",
            "Subject: Minnesota recalls McGowan (HELP!!!)\n",
            "Organization: University of Washington\n",
            "Lines: 24\n",
            "NNTP-Posting-Host: stein.u.washington.edu\n",
            "\n",
            "  Derian Hatcher's game-misconduct penalty was rescinded by the NHL, \n",
            "allowing the Minnesota defenseman to play in the North Stars' last two \n",
            "regular-season games.  Hatcher was given the penalty during a fight at \n",
            "the end of a loss at St. Louis on Sunday, April 11.  But the league \n",
            "didn't rescind the game-misconduct penalty Shane Churla received.  The \n",
            "Stars recalled center Cal McGowan from their top minor league club in \n",
            "Kalamazoo, Mich., to replace Churla.\n",
            "\n",
            "The above is courtesy of The Washington Times on-line service.\n",
            "\n",
            "Now, here's where I need help.  If anyone out there has a tape of Tuesday's\n",
            "Chicago-Minnesota game, please contact me.  Terms will be favorable.\n",
            "\n",
            "Also, if anyone can tape tonight's Minnesota-Detroit game, please contact\n",
            "me.  This could be quite important.  Once again, I will make it worth\n",
            "your trouble.\n",
            "\n",
            "Thanks to all.\n",
            "\n",
            "--\n",
            "rec.sport.hockey contact for Minnesota North Stars\n",
            "and maintainer of the r.s.h FAQ file\n",
            "Mitch McGowan a.k.a.    | KALAMAZOO WINGS  | MINNESOTA NORTH STARS |\n",
            "hamlet@u.washington.edu | ST. KILDA SAINTS | TORONTO BLUE JAYS     |\n",
            "\n"
          ]
        }
      ]
    }
  ]
}