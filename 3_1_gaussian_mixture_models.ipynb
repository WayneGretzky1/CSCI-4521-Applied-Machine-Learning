{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WayneGretzky1/CSCI-4521-Applied-Machine-Learning/blob/main/3_1_gaussian_mixture_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLDbHAxZbael"
      },
      "outputs": [],
      "source": [
        "# Load and process data\n",
        "from scipy import linalg\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Graphics/plotting libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "# Clustering algorithms\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import mixture # <- this contains the GMM\n",
        "\n",
        "import itertools\n",
        "color_iter = itertools.cycle([\"navy\", \"c\", \"cornflowerblue\", \"gold\", \"darkorange\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mickey Mouse Dataset\n",
        "\n",
        "Each small error should be its own cluster separate from the big face."
      ],
      "metadata": {
        "id": "Gtjfe9cPJXqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = 500 # Samples in each initial Gaussian\n",
        "\n",
        "# Generate random sample, two components\n",
        "np.random.seed(0)\n",
        "\n",
        "X = np.r_[\n",
        "    1.5 * np.random.randn(n_samples, 2) + np.array([0, 0]),\n",
        "    0.3 * np.random.randn(n_samples, 2) + np.array([-4, 3]),\n",
        "    0.3 * np.random.randn(n_samples, 2) + np.array([4, 3]),\n",
        "]\n",
        "X_df = pd.DataFrame(data=X, columns=[\"x\",\"y\"])\n",
        "\n",
        "sns.scatterplot(data=X_df, x=\"x\", y=\"y\")"
      ],
      "metadata": {
        "id": "mrhzGobHbhih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Means Clustering\n"
      ],
      "metadata": {
        "id": "1AO2Yw73JlYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fit k-means clustering with 3 clusters\n"
      ],
      "metadata": {
        "id": "eQGJV-a4boaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.axis('equal')\n",
        "sns.scatterplot(data=X_df, x=\"x\", y=\"y\", hue=km.labels_)"
      ],
      "metadata": {
        "id": "M6aOoQ1ybslj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-means does okay, but it does not cleanly separate the \"ear\" clusters on their own."
      ],
      "metadata": {
        "id": "f5SOTxNqJovu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GMM"
      ],
      "metadata": {
        "id": "dm8f8W0mJu4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fit a Gaussian mixture with EM\n"
      ],
      "metadata": {
        "id": "lun91uBlb49O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gmm_labels = gmm.predict(X)"
      ],
      "metadata": {
        "id": "icSMght6b8ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gmm_labels"
      ],
      "metadata": {
        "id": "1x8lO8DAb-lH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.axis('equal')\n",
        "sns.scatterplot(data=X_df, x=\"x\", y=\"y\", hue=gmm_labels)"
      ],
      "metadata": {
        "id": "yQLEy5zocAo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GMM does work perfectly. It accurately identifies that the two clusters in each top corner have small variances, so it decreases their size while increasing the size of the central cluster.\n",
        "\n",
        "K-Means cannot achieve this. It always assumes that the cluster boundary is halfway between the centroids."
      ],
      "metadata": {
        "id": "qrHsbnSvJ3yA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anisotropic Clusters\n",
        "\n",
        "Let's move to a case with two clear clusters. However, one of the clusters is anisotropicâ€”it is stretched out and rotated."
      ],
      "metadata": {
        "id": "uSQmYlzVKTrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = 500 #Samples in each initial gaussian\n",
        "\n",
        "# Generate random sample, two components\n",
        "np.random.seed(0)\n",
        "\n",
        "rot1 = np.array([[0.0, -0.1], [1.7, 0.4]])\n",
        "rot2 = np.array([[0.3, -0.1], [0.3, 1.4]])\n",
        "\n",
        "X = np.r_[\n",
        "    1.5 * np.random.randn(n_samples, 2)@rot1 + np.array([0, 0]),\n",
        "    1.0 * np.random.randn(n_samples, 2) + np.array([-2, 3]),\n",
        "]\n",
        "X_df = pd.DataFrame(data=X,columns=[\"x\",\"y\"])\n",
        "\n",
        "sns.scatterplot(data=X_df,x=\"x\",y=\"y\")"
      ],
      "metadata": {
        "id": "n1uW8i1scJXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Means"
      ],
      "metadata": {
        "id": "-51_nKxUKqq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fit k-measn clustering with 2 clusters\n"
      ],
      "metadata": {
        "id": "RXsUFV1YcO9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means struggles with anisotropic clusters. It has a circular/isotropic built-in to its distance assumptions (Voronoi cells)."
      ],
      "metadata": {
        "id": "MUFGnQGBK1f_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GMM"
      ],
      "metadata": {
        "id": "EarSdVOTLFAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fit a Gaussian mixture with EM with 2 guassians\n"
      ],
      "metadata": {
        "id": "mpY0FQzZcT3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GMM does great if you get the number of clusters right.\n",
        "\n",
        "If we try with too many clusters, it can still go wrong:"
      ],
      "metadata": {
        "id": "WUi_rSnJLHvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fit a Gaussian mixture with EM with 5 gaussians\n"
      ],
      "metadata": {
        "id": "I1DIB-aWcl4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To help with the number of clusters, we can use a Bayesian Gaussian Mixture Model. With this type of GMM, it is able to remove distributions it feels don't fit the data. This means you don't have to know exactly the right number of clusters since the model can pull the number down itself. You simply need to make a guess (always overestimate) and the Bayesian GMM will get you at least close to correct."
      ],
      "metadata": {
        "id": "ziZYzmIFHJqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fit a Dirichlet process Gaussian mixture with 3 components\n"
      ],
      "metadata": {
        "id": "STlYp7eOc_hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dp_gmm_labels"
      ],
      "metadata": {
        "id": "Yrthxl8ddN-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(dp_gmm_labels)"
      ],
      "metadata": {
        "id": "d1YI5uxYdPqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a0e23f-1bbf-4982-e72f-d42ea5b41937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 2}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(data=X_df, x=\"x\", y=\"y\", hue=dp_gmm_labels)"
      ],
      "metadata": {
        "id": "SRDTstgydU-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fit a Dirichlet process Gaussian mixture with 10 components\n"
      ],
      "metadata": {
        "id": "pL7kGbIsdcbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overlapping Clusters\n",
        "\n",
        "As a final challenge, let's consider what happens when our clusters overlap each other."
      ],
      "metadata": {
        "id": "peRurF-4MBQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = 500 # Samples in each initial Gaussian\n",
        "\n",
        "# Generate random sample, two components\n",
        "np.random.seed(0)\n",
        "\n",
        "rot1 = np.array([[0.0, -0.1], [1.7, 0.4]])\n",
        "rot2 = np.array([[0.3, -0.1], [0.3, 1.4]])\n",
        "\n",
        "X = np.r_[\n",
        "    1.5 * np.random.randn(n_samples, 2) @ rot1 + np.array([0, 0]),\n",
        "    1.0 * np.random.randn(n_samples, 2) + np.array([-2, 0]),\n",
        "]\n",
        "X_df = pd.DataFrame(data=X, columns=[\"x\",\"y\"])\n",
        "\n",
        "sns.scatterplot(data=X_df, x=\"x\", y=\"y\")"
      ],
      "metadata": {
        "id": "8Tbo0csqdkFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Means"
      ],
      "metadata": {
        "id": "7Ywh-6iWMOQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit k-means clustering\n",
        "num_clusters = 2\n",
        "km = KMeans(n_clusters=num_clusters, init='random', n_init=1, verbose=1)\n",
        "km.fit(X_df)\n",
        "sns.scatterplot(data=X_df, x=\"x\", y=\"y\", hue=km.labels_)"
      ],
      "metadata": {
        "id": "Y8qjj2KRdpfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means splits off one part of one of the clusters. There is clear room for improvement."
      ],
      "metadata": {
        "id": "f1HnJSOVMSBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GMM"
      ],
      "metadata": {
        "id": "IMOQuG73MgMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a Gaussian mixture with EM\n",
        "gmm = mixture.GaussianMixture(n_components=2, covariance_type=\"full\").fit(X)\n",
        "gmm_labels = gmm.predict(X) # Cluster new data\n",
        "sns.scatterplot(data=X_df, x=\"x\", y=\"y\", hue=gmm_labels)"
      ],
      "metadata": {
        "id": "g5179G3Dds2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GMM does perfect. It correctly creates a non-consecutive cluster. Any ambiguous points are given very reasonable labels."
      ],
      "metadata": {
        "id": "gO2wou5VMhlp"
      }
    }
  ]
}